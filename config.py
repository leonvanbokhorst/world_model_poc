# world_model_poc/config.py

# This file is for project configuration.

# Define the Ollama model to be used for inference.
# You can change this to any model you have available in Ollama (e.g., "llama3.2", "gemma3").
OLLAMA_MODEL = "gpt-oss"
